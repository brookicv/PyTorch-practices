{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "image = torch.zeros(1,3,800,800).float()\n",
    "bbox = torch.FloatTensor([[20,30,400,500],[300,400,500,600]]) # y1,x1,y2,x2\n",
    "labels = torch.LongTensor([6,8]) # 0 represents background\n",
    "sub_sample = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "30\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "vgg = torchvision.models.vgg16(pretrained=True)\n",
    "fee =[]\n",
    "x = image.clone()\n",
    "for k,v in vgg.features.named_children():\n",
    "    x = v(x)\n",
    "    if x.size()[2] < 800 // 16:\n",
    "        print(k,v)\n",
    "        break\n",
    "    fee.append(v)\n",
    "    out_channels = x.size()[1]\n",
    "    \n",
    "print(len(fee))\n",
    "print(out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "faster_rcnn_extractor = nn.Sequential(*fee)\n",
    "print(faster_rcnn_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "out_map = faster_rcnn_extractor(image)\n",
    "print(out_map.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 生成Anchor Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ratio = [0.5,1,2]\n",
    "anchor_scales = [8,16,32]\n",
    "\n",
    "anchor_base = np.zeros((len(ratio) * len(anchor_scales),4),dtype=np.float32) # y1,x1,y2,x2\n",
    "print(anchor_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0 8.0\n",
      "[[ -37.254833  -82.50967    53.254833   98.50967 ]\n",
      " [ -82.50967  -173.01933    98.50967   189.01933 ]\n",
      " [-173.01933  -354.03867   189.01933   370.03867 ]\n",
      " [ -56.        -56.         72.         72.      ]\n",
      " [-120.       -120.        136.        136.      ]\n",
      " [-248.       -248.        264.        264.      ]\n",
      " [ -82.50967   -37.254833   98.50967    53.254833]\n",
      " [-173.01933   -82.50967   189.01933    98.50967 ]\n",
      " [-354.03867  -173.01933   370.03867   189.01933 ]]\n"
     ]
    }
   ],
   "source": [
    "ctr_y = sub_sample / 2\n",
    "ctr_x = sub_sample / 2\n",
    "print(ctr_y,ctr_x)\n",
    "\n",
    "for i in range(len(ratio)):\n",
    "    for j in range(len(anchor_scales)):\n",
    "        h = sub_sample * anchor_scales[j] * np.sqrt(ratio[i])\n",
    "        w = sub_sample * anchor_scales[j] * np.sqrt(1. / ratio[i])\n",
    "        \n",
    "        index = i * len(anchor_scales) + j\n",
    "        \n",
    "        anchor_base[index,0] = ctr_y - h / 2\n",
    "        anchor_base[index,1] = ctr_x - w / 2\n",
    "        anchor_base[index,2] = ctr_y + h / 2\n",
    "        anchor_base[index,3] = ctr_x + w / 2\n",
    "        \n",
    "print(anchor_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[ 16  32  48  64  80  96 112 128 144 160 176 192 208 224 240 256 272 288\n",
      " 304 320 336 352 368 384 400 416 432 448 464 480 496 512 528 544 560 576\n",
      " 592 608 624 640 656 672 688 704 720 736 752 768 784 800]\n",
      "[ 16  32  48  64  80  96 112 128 144 160 176 192 208 224 240 256 272 288\n",
      " 304 320 336 352 368 384 400 416 432 448 464 480 496 512 528 544 560 576\n",
      " 592 608 624 640 656 672 688 704 720 736 752 768 784 800]\n"
     ]
    }
   ],
   "source": [
    "fe_size = (800 // 16)\n",
    "ctr_x = np.arange(16,(fe_size + 1) * 16,16)\n",
    "ctr_y = np.arange(16,(fe_size + 1) * 16,16)\n",
    "print(fe_size)\n",
    "print(ctr_x)\n",
    "print(ctr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.   8.]\n",
      " [ 24.   8.]\n",
      " [ 40.   8.]\n",
      " ...\n",
      " [760. 792.]\n",
      " [776. 792.]\n",
      " [792. 792.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "ctr = np.zeros((len(ctr_x) * len(ctr_y),2))\n",
    "for x in range(len(ctr_x)):\n",
    "    for y in range(len(ctr_y)):\n",
    "        ctr[index,1] = ctr_x[x] - 8\n",
    "        ctr[index,0] = ctr_y[y] - 8\n",
    "        index += 1\n",
    "        \n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 4)\n"
     ]
    }
   ],
   "source": [
    "anchors = np.zeros((fe_size * fe_size * 9,4)) # 每个中心点生成9个anchor boxes,y1,x1,y2,x2\n",
    "\n",
    "index = 0\n",
    "for c in ctr:\n",
    "    ctr_y,ctr_x = c\n",
    "    for i in range(len(ratio)):\n",
    "        for j in range(len(anchor_scales)):\n",
    "            h = sub_sample * anchor_scales[j] * np.sqrt(ratio[i])\n",
    "            w = sub_sample * anchor_scales[j] * np.sqrt(1. / ratio[i])\n",
    "        \n",
    "            anchors[index,0] = ctr_y - h / 2\n",
    "            anchors[index,1] = ctr_x - w / 2\n",
    "            anchors[index,2] = ctr_y + h / 2\n",
    "            anchors[index,3] = ctr_x + w / 2\n",
    "            \n",
    "            index += 1\n",
    "print(anchors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-37.254834   -82.50966799  53.254834    98.50966799]\n"
     ]
    }
   ],
   "source": [
    "print(anchors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  93.49033201 -173.01933598  274.50966799  189.01933598]\n"
     ]
    }
   ],
   "source": [
    "print(anchors[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已经生成所有的ａｎｃｈｏｒ　ｂｏｘｅｓ完毕，下面就需要给每个anchor box打上标签，以及该ａｎｃｈｏｒ　ｂｏｘ所对应的目标,若果anchor boxe和目标的ground-truth-box的ＩｏＵ　大于等于0.7，则为该ａｎｃｈｏｒ打上positive label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anchor boxes 标签\n",
    "根据目标的ground truth，以ｉｏｕ的值为根据，为每个ａｎｃｈｏｒ　ｂｏｘ打上标签，表示该ａｎｃｈｏｒ　ｂｏｘ是否包含目标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n"
     ]
    }
   ],
   "source": [
    "index_inside = np.where(\n",
    "    (anchors[:,0] >= 0) &\n",
    "    (anchors[:,1] >= 0) &\n",
    "    (anchors[:,2] <= 800) &\n",
    "    (anchors[:,3] <= 800)\n",
    ")[0]\n",
    "print(index_inside.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n"
     ]
    }
   ],
   "source": [
    "label = np.empty((len(index_inside),),dtype=np.int32)\n",
    "label.fill(-1)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940, 4)\n",
      "[ 13.49033201  10.745166   194.50966799 101.254834  ]\n"
     ]
    }
   ],
   "source": [
    "valid_anchor_boxes = anchors[index_inside]\n",
    "print(valid_anchor_boxes.shape)\n",
    "print(valid_anchor_boxes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 20.,  30., 400., 500.],\n",
      "        [300., 400., 500., 600.]])\n",
      "(8940, 2)\n",
      "[False False]\n"
     ]
    }
   ],
   "source": [
    "ious = np.empty((len(valid_anchor_boxes),2),dtype=np.float32)\n",
    "ious.fill(0)\n",
    "print(bbox)\n",
    "for num1,i in enumerate(valid_anchor_boxes):\n",
    "    ya1,xa1,ya2,xa2 = i\n",
    "    anchor_area = (ya2 - ya1) * (xa2 - xa1)\n",
    "    for num2,j in enumerate(bbox):\n",
    "        yb1,xb1,yb2,xb2 = j\n",
    "        box_area = (yb2 - yb1) * (xb2 - xb1)\n",
    "        \n",
    "        inter_x1 = max([xb1,xa1])\n",
    "        inter_y1 = max([yb1,ya1])\n",
    "        inter_x2 = min([xb2,xa2])\n",
    "        inter_y2 = min([yb2,ya2])\n",
    "        \n",
    "        if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
    "            iter_area = (inter_y2 - inter_y1) * (inter_x2 - inter_x1)\n",
    "            iou = iter_area / (anchor_area + box_area - iter_area)\n",
    "        else:\n",
    "            iou = 0.\n",
    "        \n",
    "        ious[num1,num2] = iou\n",
    "        \n",
    "print(ious.shape)\n",
    "print((ious > 0.7)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2262 5620]\n",
      "[0.68130493 0.61035156]\n"
     ]
    }
   ],
   "source": [
    "gt_argmax_ious = ious.argmax(axis=0)\n",
    "print(gt_argmax_ious)\n",
    "\n",
    "gt_max_ious = ious[gt_argmax_ious,np.arange(ious.shape[1])]\n",
    "print(gt_max_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0.06811669 0.07083762 0.07083762 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "argmax_ious = ious.argmax(axis=1)\n",
    "print(argmax_ious.shape)\n",
    "print(argmax_ious)\n",
    "max_ious = ious[np.arange(len(index_inside)),argmax_ious]\n",
    "print(max_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_iou_threshold = 0.7\n",
    "neg_iou_threshold = 0.3\n",
    "\n",
    "label[max_ious < neg_iou_threshold] = 0\n",
    "label[max_ious > pos_iou_threshold] = 1\n",
    "label[gt_argmax_ious] = 1 # 和gt-box的ｉｏｕ最大的设为positive,这是防止gt-box和每个ａｎｃｈｏｒ　ｂｏｘ的ｉｏｕ都小于pos_iou_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ４．选择anchor box\n",
    "将图像的目标划分到具体的anchor box后，就需要将这些ａｎｃｈｏｒ box输入到ＲＰＮ网络中。　\n",
    "随机的采样２５６个ａｎｃｈｏｒ　ｂｏｘ来计算mini-batch的损失函数，其中具有正标签和负标签的anchor box的比例为1:1。　如果一幅图像中的负ａｎｃｈｏｒ box的个数少于１２８，则使用其他的负anchor box填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ration = 0.5\n",
    "n_sample = 256\n",
    "n_pos = pos_ration * n_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从正标签的anchor box中随机的选择n_pos个，忽略(-1)的ａｎｃｈｏｒ　ｂｏｘ。如果正样本的个数少于n_pos，则从负样本中随机选择，进行填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = np.where(label == 1)[0]\n",
    "if len(pos_index) > n_pos:\n",
    "    disable_index = np.random.choice(pos_index,size=(len(pos_index) - n_pos),replace=False)\n",
    "    label[disable_index] = -1\n",
    "    \n",
    "n_neg = n_sample - np.sum(label == 1)\n",
    "neg_index = np.where(label == 0)[0]\n",
    "if len(neg_index) > n_neg:\n",
    "    disable_index = np.random.choice(neg_index,size=(len(neg_index) - n_neg),replace=False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. anchor 定位\n",
    "现在ａｎｃｈｏｒ　ｂｏｘ的位置信息是其在图像上的绝对位置，现需要将其改为相对于ground truth box的偏移位置，相对于和其有最大IoU的ＧＴ_box的偏移。转换公式如下：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "t_x &= (x - x_a) / w_a \\\\\n",
    "t_y &= (y-y_a) / h_a \\\\\n",
    "t_w &= log(w / w_a) \\\\\n",
    "t_h &= log(h / h_a)\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中，$x,y,w,h$为Ground truth box的中心坐标，宽和高；$x_a,y_a,w_a,h_a$为ａｎｃｈｏｒ　ｂｏｘｅｓ的中心坐标，宽和高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 对于每个anchor box要找到和其有最大IoU的ground truth box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]\n",
      " ...\n",
      " [ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]\n",
      " [ 20.  30. 400. 500.]]\n"
     ]
    }
   ],
   "source": [
    "max_iou_bbox = bbox[argmax_ious].detach().numpy()\n",
    "print(max_iou_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. anchor box的格式为$y_1,x_1,y_2,x_2$需要对其进行转换，转换为中心点，宽，高的表示方法，$ctr_x,ctr_y,h,w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = valid_anchor_boxes[:,2] - valid_anchor_boxes[:,0]\n",
    "width = valid_anchor_boxes[:,3] - valid_anchor_boxes[:,1]\n",
    "ctr_y = valid_anchor_boxes[:,0] + 0.5 * height\n",
    "ctr_x = valid_anchor_boxes[:,1] + 0.5 * width\n",
    "\n",
    "base_height = max_iou_bbox[:,2] - max_iou_bbox[:,0]\n",
    "base_width = max_iou_bbox[:,3] - max_iou_bbox[:,1]\n",
    "base_ctr_y = max_iou_bbox[:,0] + 0.5 * base_height\n",
    "base_ctr_x = max_iou_bbox[:,1] + 0.5 * base_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[ 0.5855728   2.30914558  0.7415674   1.64727602]\n",
      " [ 0.49718446  2.30914558  0.7415674   1.64727602]\n",
      " [ 0.40879611  2.30914558  0.7415674   1.64727602]\n",
      " ...\n",
      " [-2.50801936 -5.29225232  0.7415674   1.64727602]\n",
      " [-2.59640771 -5.29225232  0.7415674   1.64727602]\n",
      " [-2.68479606 -5.29225232  0.7415674   1.64727602]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(max_iou_bbox))\n",
    "\n",
    "# 利用公式，找到每个ａｎｃｈｏｒ　ｂｏｘ相对于ｇｔ box的偏移量\n",
    "eps = np.finfo(height.dtype).eps\n",
    "height = np.maximum(height,eps)\n",
    "widht = np.maximum(width,eps)\n",
    "dy = (base_ctr_y - ctr_y ) / height\n",
    "dx = (base_ctr_x - ctr_x) / width\n",
    "dh = np.log(base_height / height)\n",
    "dw = np.log(base_width / width)\n",
    "\n",
    "anchor_locs = np.vstack((dy,dx,dh,dw)).transpose()\n",
    "print(anchor_locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到了每个ａｎｃｈｏｒ　ｂｏｘ相对于ｇｔ_box的偏移量以及相关的标签，为每个ａｎｃｈｏｒ　ｂｏｘ进行赋值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_labels = np.empty((len(anchors),),dtype=label.dtype)\n",
    "anchor_labels.fill(-1)\n",
    "anchor_labels[index_inside] = label\n",
    "\n",
    "# 坐标\n",
    "anchor_locations = np.empty((len(anchors),) + anchors.shape[1:],dtype=anchor_locs.dtype)\n",
    "anchor_locations.fill(0)\n",
    "anchor_locations[index_inside,:] = anchor_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500,)\n",
      "(22500, 4)\n"
     ]
    }
   ],
   "source": [
    "print(anchor_labels.shape)\n",
    "print(anchor_locations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RPN\n",
    "为了生成region proposals，在特征提取模块得到的特征层上使用一个滑动窗口，将滑动窗口内的$3 \\times 3$特征作为ＲＰＮ网络的输入，每个滑动窗口映射到更低的维度(512)，然后将该特征输入到两个全连接层中：　\n",
    "１．边框回顾层\n",
    "２．边框分类层\n",
    "\n",
    "Ｆａｓｔｅｒ R-CNN 中使用$ 3\\times 3$的滑动窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "mid_channels = 512 \n",
    "in_channels = 512 # 和特征提取网络最终的输出有关，ｖｇｇ１６最终输出的ｆｅａｔｕｒｅ　ｍａｐ的channels 为５１２\n",
    "n_anchor = 9 # 每个ｆｅａｔｕｒｅ　ｍａｐ的位置生成的ａｎｃｈｏｒ　ｂｏｘ的个数\n",
    "\n",
    "conv1 = nn.Conv2d(in_channels,mid_channels,3,1,1)\n",
    "reg_layer = nn.Conv2d(mid_channels,n_anchor * 4,1,1,0) # 1 * 1卷积层，用着边框回归\n",
    "cls_layer = nn.Conv2d(mid_channels,n_anchor * 2,1,1,0) # 1 * 1 卷积层,用于边框分类\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化\n",
    "nn.init.xavier_uniform_(conv1.weight.data)\n",
    "nn.init.constant_(conv1.bias.data,0)\n",
    "\n",
    "nn.init.xavier_uniform_(reg_layer.weight.data)\n",
    "nn.init.constant_(reg_layer.bias.data,0)\n",
    "\n",
    "nn.init.xavier_uniform_(cls_layer.weight.data)\n",
    "nn.init.constant_(cls_layer.bias.data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36, 50, 50]) torch.Size([1, 18, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "x = conv1(out_map)\n",
    "pred_anchor_locs = reg_layer(x)\n",
    "pred_anchor_cls = cls_layer(x)\n",
    "\n",
    "print(pred_anchor_locs.shape,pred_anchor_cls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22500, 4])\n"
     ]
    }
   ],
   "source": [
    "pred_anchor_locs = pred_anchor_locs.permute(0,2,3,1).contiguous().view(1,-1,4)\n",
    "print(pred_anchor_locs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 50, 18])\n"
     ]
    }
   ],
   "source": [
    "pred_anchor_cls = pred_anchor_cls.permute(0,2,3,1).contiguous()\n",
    "print(pred_anchor_cls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22500])\n"
     ]
    }
   ],
   "source": [
    "objectness_score = pred_anchor_cls.view(1,50,50,9,2)[:,:,:,:,1].contiguous().view(1,-1)\n",
    "print(objectness_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22500, 2])\n"
     ]
    }
   ],
   "source": [
    "pred_anchor_cls = pred_anchor_cls.view(1,-1,2)\n",
    "print(pred_anchor_cls.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.生成proposal region\n",
    "\n",
    "ＲＰＮ网络直接生成的proposals的彼此的重叠度较高，为了减少冗余，可以根据proposals regions的ｃｌｓ分数对其进行ＮＭＳ。将NMS的ｉｏｕ阈值设为０．７，这样一幅图像大约有２０００个proposal regions。　经过NMS后的top-n的ｐｒｏｐｏｓａｌ　ｒｅｇｉｏｎ区域输入到后续的网络中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_threshold = 0.7\n",
    "n_train_pre_nms = 12000 #  训练时，ｎｍｓ之前的ｂｂｏｘ数\n",
    "n_train_post_nms = 2000 # 训练时，ｎｍｓ之后的ｂｂｏｘ数\n",
    "n_test_pre_nms = 6000\n",
    "n_test_post_nms = 300\n",
    "\n",
    "min_size = 16 # proposal region的最小高度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对ＲＰＮ生成的proposal region进行一下处理\n",
    "- 转换ＲＰＮ网络生成的bbox的表示为[y1,x1,y2,x2]格式\n",
    "- 将预测框变换到原图像上\n",
    "- 去除高度或者宽度小于min_size\n",
    "- 通过边框回归的分数对生成的ｂｂｏｘ进行排序\n",
    "- 取top-n(n = 12000,6000)的ｂｂｏｘ进行ｎｍｓ\n",
    "- 取top-n(n = 2000,300)的ｂｂｏｘ输入到后续网络中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_height = anchors[:,2] - anchors[:,0]\n",
    "anc_width = anchors[:,3] - anchors[:,1]\n",
    "anc_ctr_y = anchors[:,0] + 0.5 * anc_height\n",
    "anc_ctr_x = anchors[:,1] + 0.5 * anc_width\n",
    "\n",
    "# 转换ｂｂｏｘ的表示格式为[y1,x1,y2,x2]\n",
    "pred_anchor_locs_numpy = pred_anchor_locs[0].detach().numpy()\n",
    "pred_anchor_cls_numpy = pred_anchor_cls[0].detach().numpy()\n",
    "\n",
    "dy = pred_anchor_locs_numpy[:,0::4]\n",
    "dx = pred_anchor_locs_numpy[:,1::4]\n",
    "dh = pred_anchor_locs_numpy[:,2::4]\n",
    "dw = pred_anchor_locs_numpy[:,3::4]\n",
    "\n",
    "ctr_y = dy * anc_height[:,np.newaxis] + anc_ctr_y[:,np.newaxis]\n",
    "ctr_x = dy * anc_width[:,np.newaxis] + anc_ctr_x[:,np.newaxis]\n",
    "h = np.exp(dh) * anc_height[:,np.newaxis]\n",
    "w = np.exp(dw) * anc_width[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -37.7658062  -123.88712949   26.28689447   84.92930603]\n",
      " [-116.79459309 -179.55371864  109.51764258  148.99981762]\n",
      " [ -94.85263355 -222.93101236  184.65372091  386.53318707]\n",
      " ...\n",
      " [ 665.93414467  736.99190782  856.73858432  816.34445668]\n",
      " [ 644.51383499  734.26177389 1043.37967601  901.68498161]\n",
      " [ 657.39737536  715.21259601 1271.19769652 1041.08493993]]\n"
     ]
    }
   ],
   "source": [
    "roi = np.zeros(pred_anchor_locs_numpy.shape)\n",
    "roi[:,0::4] = ctr_y - 0.5 * h\n",
    "roi[:,1::4] = ctr_x - 0.5 * w\n",
    "roi[:,2::4] = ctr_y + 0.5 * h\n",
    "roi[:,3::4] = ctr_x + 0.5 * w\n",
    "\n",
    "print(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           0.          26.28689447  84.92930603]\n",
      " [  0.           0.         109.51764258 148.99981762]\n",
      " [  0.           0.         184.65372091 386.53318707]\n",
      " ...\n",
      " [665.93414467 736.99190782 800.         800.        ]\n",
      " [644.51383499 734.26177389 800.         800.        ]\n",
      " [657.39737536 715.21259601 800.         800.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 变换到图像上\n",
    "img_size = (800,800)\n",
    "roi[:,slice(0,4,2)] = np.clip(roi[:,slice(0,4,2)],0,img_size[0])\n",
    "roi[:,slice(1,4,2)] = np.clip(roi[:,slice(1,4,2)],0,img_size[1])\n",
    "print(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22500, 1)\n",
      "(22452, 1)\n"
     ]
    }
   ],
   "source": [
    "# 移除宽度或者高度小于min_size的ｂｂｏｘ\n",
    "hs = roi[:,2] - roi[:,0]\n",
    "ws = roi[:,3] - roi[:,1]\n",
    "keep = np.where((hs >= min_size) & (ws >= min_size))[0]\n",
    "roi = roi[keep,:]\n",
    "\n",
    "objectness_score_numpy = objectness_score.detach().numpy().transpose()\n",
    "print(objectness_score_numpy.shape)\n",
    "score = objectness_score_numpy[keep]\n",
    "print(score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   17   386 22018 ...   848   847   416]\n"
     ]
    }
   ],
   "source": [
    "# 按分数排序\n",
    "order = score.ravel().argsort()[::]\n",
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 4)\n",
      "[[  2.11249716   0.          69.98696347  88.74517245]\n",
      " [730.96738442   0.         797.76979135  81.0950946 ]\n",
      " [  0.         767.48766804 341.8061843  800.        ]\n",
      " ...\n",
      " [156.89227104 529.78638268 272.62911797 667.73500633]\n",
      " [332.89227104 577.78638268 448.62911797 715.73500633]\n",
      " [588.89227104 577.78638268 704.62911797 715.73500633]]\n"
     ]
    }
   ],
   "source": [
    "order = order[:n_train_pre_nms]\n",
    "roi = roi[order,:]\n",
    "\n",
    "print(roi.shape)\n",
    "print(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22452, 1)\n",
      "[0]\n",
      "(1, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liqiang/.conda/envs/pytorch_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:32: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "# nms\n",
    "y1 = roi[:,0]\n",
    "x1 = roi[:,1]\n",
    "y2 = roi[:,2]\n",
    "x2 = roi[:,3]\n",
    "\n",
    "area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "order = score.argsort()[::]\n",
    "keep = []\n",
    "\n",
    "print(order.shape)\n",
    "\n",
    "while order.size > 0:\n",
    "    i = order[0]\n",
    "    print(i)\n",
    "    xx1 = np.maximum(x1[i],x1[order[1:]])\n",
    "    yy1 = np.maximum(y1[i],y1[order[1:]])\n",
    "    xx2 = np.minimum(x2[i],x2[order[1:]])\n",
    "    yy2 = np.minimum(y2[i],y2[order[1:]])\n",
    "    \n",
    "    w = np.maximum(0.0,xx2 - xx1 + 1)\n",
    "    h = np.maximum(0.0,yy2 - yy1 + 1)\n",
    "    inter = w * h\n",
    "    ovr = inter / (area[i] + area[order[1::]] - inter)\n",
    "    \n",
    "    inds = np.where(ovr <= nms_threshold)[0]\n",
    "    \n",
    "    order = order[inds + 1]\n",
    "    \n",
    "    keep.append(i)\n",
    "keep = keep[:n_train_post_nms]\n",
    "roi = roi[keep]\n",
    "\n",
    "print(roi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python[pytorch_gpu]",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
